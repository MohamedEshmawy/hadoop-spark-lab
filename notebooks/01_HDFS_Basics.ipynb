{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: HDFS Basics\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand HDFS architecture (NameNode, DataNodes, blocks)\n",
    "- Perform file operations: upload, list, download, delete\n",
    "- Explore replication factor and block concepts\n",
    "- Use the HDFS Web UI to visualize the filesystem\n",
    "\n",
    "## Prerequisites\n",
    "- Cluster is running (`./scripts/start-lab.sh`)\n",
    "- Sanity checks passed\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Exploring HDFS Commands\n",
    "\n",
    "HDFS commands are similar to Linux filesystem commands, but prefixed with `hdfs dfs -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "drwxrwxrwt   - root supergroup          0 2026-01-16 01:08 /spark-logs\n",
      "drwxr-xr-x   - root supergroup          0 2026-01-16 01:08 /tmp\n",
      "drwxr-xr-x   - root supergroup          0 2026-01-16 01:08 /user\n"
     ]
    }
   ],
   "source": [
    "# List the root directory of HDFS\n",
    "!hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory in HDFS for our exercises\n",
    "!hdfs dfs -mkdir -p /user/student/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - jovyan supergroup          0 2026-01-10 22:08 /user/student/data\n"
     ]
    }
   ],
   "source": [
    "# Verify the directory was created\n",
    "!hdfs dfs -ls /user/student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Uploading Files to HDFS\n",
    "\n",
    "Let's upload our sample data to HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8832\n",
      "drwxrwxrwx 1 root root    4096 Jan  8 23:58 .\n",
      "drwxrwxrwx 1 root root    4096 Jan  8 23:58 ..\n",
      "-rwxrwxrwx 1 root root 9040461 Jan  8 23:58 transactions.csv\n"
     ]
    }
   ],
   "source": [
    "# Check what files are available locally\n",
    "!ls -la /home/jovyan/data/sales/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the transactions file to HDFS\n",
    "!hdfs dfs -put /home/jovyan/data/sales/transactions.csv /user/student/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload products catalog\n",
    "!hdfs dfs -put /home/jovyan/data/products/catalog.csv /user/student/data/\n",
    "!hdfs dfs -put /home/jovyan/data/products/catalog.json /user/student/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   3 jovyan supergroup     34.8 K 2026-01-10 22:09 /user/student/data/catalog.csv\n",
      "-rw-r--r--   3 jovyan supergroup     96.7 K 2026-01-10 22:09 /user/student/data/catalog.json\n",
      "-rw-r--r--   3 jovyan supergroup      8.6 M 2026-01-10 22:09 /user/student/data/transactions.csv\n"
     ]
    }
   ],
   "source": [
    "# Verify uploads\n",
    "!hdfs dfs -ls -h /user/student/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understanding Blocks and Replication\n",
    "\n",
    "HDFS splits large files into blocks (default 128MB in production, 16MB in our lab).\n",
    "Each block is replicated across multiple DataNodes for fault tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to namenode via http://namenode:9870/fsck?ugi=jovyan&files=1&blocks=1&locations=1&path=%2Fuser%2Fstudent%2Fdata%2Ftransactions.csv\n",
      "FSCK started by jovyan (auth:SIMPLE) from /172.28.0.13 for path /user/student/data/transactions.csv at Sat Jan 10 22:09:52 UTC 2026\n",
      "\n",
      "/user/student/data/transactions.csv 9040461 bytes, replicated: replication=3, 1 block(s):  OK\n",
      "0. BP-528258548-172.28.0.3-1768082688920:blk_1073741825_1001 len=9040461 Live_repl=3  [DatanodeInfoWithStorage[172.28.0.6:9866,DS-89344feb-57d4-48bb-afb5-852412929d1a,DISK], DatanodeInfoWithStorage[172.28.0.8:9866,DS-163cc9d4-5be8-48fe-93ca-6f3139fabc8b,DISK], DatanodeInfoWithStorage[172.28.0.4:9866,DS-40d953a5-006d-4de7-a723-c727328b5b2e,DISK]]\n",
      "\n",
      "\n",
      "Status: HEALTHY\n",
      " Number of data-nodes:\t3\n",
      " Number of racks:\t\t1\n",
      " Total dirs:\t\t\t0\n",
      " Total symlinks:\t\t0\n",
      "\n",
      "Replicated Blocks:\n",
      " Total size:\t9040461 B\n",
      " Total files:\t1\n",
      " Total blocks (validated):\t1 (avg. block size 9040461 B)\n",
      " Minimally replicated blocks:\t1 (100.0 %)\n",
      " Over-replicated blocks:\t0 (0.0 %)\n",
      " Under-replicated blocks:\t0 (0.0 %)\n",
      " Mis-replicated blocks:\t\t0 (0.0 %)\n",
      " Default replication factor:\t2\n",
      " Average block replication:\t3.0\n",
      " Missing blocks:\t\t0\n",
      " Corrupt blocks:\t\t0\n",
      " Missing replicas:\t\t0 (0.0 %)\n",
      " Blocks queued for replication:\t0\n",
      "\n",
      "Erasure Coded Block Groups:\n",
      " Total size:\t0 B\n",
      " Total files:\t0\n",
      " Total block groups (validated):\t0\n",
      " Minimally erasure-coded block groups:\t0\n",
      " Over-erasure-coded block groups:\t0\n",
      " Under-erasure-coded block groups:\t0\n",
      " Unsatisfactory placement block groups:\t0\n",
      " Average block group size:\t0.0\n",
      " Missing block groups:\t\t0\n",
      " Corrupt block groups:\t\t0\n",
      " Missing internal blocks:\t0\n",
      " Blocks queued for replication:\t0\n",
      "FSCK ended at Sat Jan 10 22:09:52 UTC 2026 in 5 milliseconds\n",
      "\n",
      "\n",
      "The filesystem under path '/user/student/data/transactions.csv' is HEALTHY\n"
     ]
    }
   ],
   "source": [
    "# Check block information for our file\n",
    "!hdfs fsck /user/student/data/transactions.csv -files -blocks -locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Check the current replication factor\n",
    "!hdfs dfs -stat '%r' /user/student/data/transactions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication 2 set: /user/student/data/transactions.csv\n"
     ]
    }
   ],
   "source": [
    "# Change replication factor to 3\n",
    "!hdfs dfs -setrep 2 /user/student/data/transactions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to namenode via http://namenode:9870/fsck?ugi=jovyan&files=1&blocks=1&locations=1&path=%2Fuser%2Fstudent%2Fdata%2Ftransactions.csv\n",
      "FSCK started by jovyan (auth:SIMPLE) from /172.28.0.11 for path /user/student/data/transactions.csv at Sat Jan 10 21:14:24 UTC 2026\n",
      "\n",
      "/user/student/data/transactions.csv 9040461 bytes, replicated: replication=2, 1 block(s):  OK\n",
      "0. BP-1325781439-172.28.0.2-1767962107483:blk_1073741841_1017 len=9040461 Live_repl=2  [DatanodeInfoWithStorage[172.28.0.3:9866,DS-526900cf-c0fc-45b6-896c-bfb736c4af98,DISK], DatanodeInfoWithStorage[172.28.0.5:9866,DS-a4b88363-9556-4743-bfa2-bb6a13741051,DISK], DatanodeInfoWithStorage[172.28.0.4:9866,DS-6704a6a5-4cf5-48d4-8ee8-5a87e7c7a28c,DISK]]\n",
      "\n",
      "\n",
      "Status: HEALTHY\n",
      " Number of data-nodes:\t3\n",
      " Number of racks:\t\t1\n",
      " Total dirs:\t\t\t0\n",
      " Total symlinks:\t\t0\n",
      "\n",
      "Replicated Blocks:\n",
      " Total size:\t9040461 B\n",
      " Total files:\t1\n",
      " Total blocks (validated):\t1 (avg. block size 9040461 B)\n",
      " Minimally replicated blocks:\t1 (100.0 %)\n",
      " Over-replicated blocks:\t0 (0.0 %)\n",
      " Under-replicated blocks:\t0 (0.0 %)\n",
      " Mis-replicated blocks:\t\t0 (0.0 %)\n",
      " Default replication factor:\t2\n",
      " Average block replication:\t2.0\n",
      " Missing blocks:\t\t0\n",
      " Corrupt blocks:\t\t0\n",
      " Missing replicas:\t\t0 (0.0 %)\n",
      " Blocks queued for replication:\t0\n",
      "\n",
      "Erasure Coded Block Groups:\n",
      " Total size:\t0 B\n",
      " Total files:\t0\n",
      " Total block groups (validated):\t0\n",
      " Minimally erasure-coded block groups:\t0\n",
      " Over-erasure-coded block groups:\t0\n",
      " Under-erasure-coded block groups:\t0\n",
      " Unsatisfactory placement block groups:\t0\n",
      " Average block group size:\t0.0\n",
      " Missing block groups:\t\t0\n",
      " Corrupt block groups:\t\t0\n",
      " Missing internal blocks:\t0\n",
      " Blocks queued for replication:\t0\n",
      "FSCK ended at Sat Jan 10 21:14:24 UTC 2026 in 2 milliseconds\n",
      "\n",
      "\n",
      "The filesystem under path '/user/student/data/transactions.csv' is HEALTHY\n"
     ]
    }
   ],
   "source": [
    "# Verify the new replication factor\n",
    "!hdfs fsck /user/student/data/transactions.csv -files -blocks -locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Checkpoint Question 1\n",
    "Open the HDFS NameNode UI at http://localhost:9870 and navigate to:\n",
    "**Utilities ‚Üí Browse the file system**\n",
    "\n",
    "Find the `transactions.csv` file. \n",
    "- How many blocks does it have?\n",
    "- What is the block size?\n",
    "- On which DataNodes are the blocks stored?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n",
    "(Write your observations here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Reading Files from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transaction_id,transaction_date,transaction_time,customer_id,product_id,quantity,unit_price,total_amount,payment_method,store_region,is_online\n",
      "TXN00000001,2024-06-03,11:56:54,CUST000481,PROD00352,1,259.06,259.06,PayPal,North,True\n",
      "TXN00000002,2023-11-22,14:25:51,CUST001581,PROD00288,6,442.7,2656.2,PayPal,Central,False\n",
      "TXN00000003,2023-08-13,13:40:52,CUST000534,PROD00205,1,116.0,116.0,Credit Card,Central,False\n",
      "TXN00000004,2023-06-20,16:13:49,CUST000840,PROD00230,4,187.53,750.12,Credit Card,North,False\n",
      "TXN00000005,2024-01-24,09:49:45,CUST001239,PROD00067,9,5.14,46.28,Cash,South,False\n",
      "TXN00000006,2023-08-04,13:34:12,CUST001569,PROD00393,9,36.53,328.74,Debit Card,East,False\n",
      "TXN00000007,2023-06-15,13:21:26,CUST001471,PROD00441,4,197.29,789.16,Debit Card,Central,True\n",
      "TXN00000008,2024-06-23,09:32:25,CUST000028,PROD00482,1,477.45,477.45,PayPal,North,True\n",
      "TXN00000009,2024-12-05,11:02:17,CUST000580,PROD00081,5,193.65,968.26,Credit Card,West,False\n",
      "TXN00000010,2023-10-04,21:05:04,CUST000821,PROD00336,3,97.22,291"
     ]
    }
   ],
   "source": [
    "# Preview the first few lines\n",
    "!hdfs dfs -head /user/student/data/transactions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100001\n"
     ]
    }
   ],
   "source": [
    "# Count total lines\n",
    "!hdfs dfs -cat /user/student/data/transactions.csv | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.8 K  104.4 K  /user/student/data/catalog.csv\n",
      "96.7 K  290.2 K  /user/student/data/catalog.json\n",
      "8.6 M   17.2 M   /user/student/data/transactions.csv\n"
     ]
    }
   ],
   "source": [
    "# Get file statistics\n",
    "!hdfs dfs -du -h /user/student/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Cluster Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured Capacity: 12001952649216 (10.92 TB)\n",
      "Present Capacity: 109698896723 (102.17 GB)\n",
      "DFS Remaining: 109680267264 (102.15 GB)\n",
      "DFS Used: 18629459 (17.77 MB)\n",
      "DFS Used%: 0.02%\n",
      "Replicated Blocks:\n",
      "\tUnder replicated blocks: 0\n",
      "\tBlocks with corrupt replicas: 0\n",
      "\tMissing blocks: 0\n",
      "\tMissing blocks (with replication factor 1): 0\n",
      "\tLow redundancy blocks with highest priority to recover: 0\n",
      "\tPending deletion blocks: 0\n",
      "Erasure Coded Block Groups: \n",
      "\tLow redundancy block groups: 0\n",
      "\tBlock groups with corrupt internal blocks: 0\n",
      "\tMissing block groups: 0\n",
      "\tLow redundancy blocks with highest priority to recover: 0\n",
      "\tPending deletion blocks: 0\n",
      "\n",
      "-------------------------------------------------\n",
      "Live datanodes (3):\n",
      "\n",
      "Name: 172.28.0.4:9866 (datanode1.hadoop_hadoop-network)\n",
      "Hostname: datanode1\n",
      "Decommission Status : Normal\n",
      "Configured Capacity: 4000650883072 (3.64 TB)\n",
      "DFS Used: 9246853 (8.82 MB)\n",
      "Non DFS Used: 3964081547131 (3.61 TB)\n",
      "DFS Remaining: 36560089088 (34.05 GB)\n",
      "DFS Used%: 0.00%\n",
      "DFS Remaining%: 0.91%\n",
      "Configured Cache Capacity: 0 (0 B)\n",
      "Cache Used: 0 (0 B)\n",
      "Cache Remaining: 0 (0 B)\n",
      "Cache Used%: 100.00%\n",
      "Cache Remaining%: 0.00%\n",
      "Xceivers: 0\n",
      "Last contact: Sat Jan 10 22:14:06 UTC 2026\n",
      "Last Block Report: Sat Jan 10 22:05:05 UTC 2026\n",
      "Num of Blocks: 3\n",
      "\n",
      "\n",
      "Name: 172.28.0.6:9866 (datanode3.hadoop_hadoop-network)\n",
      "Hostname: datanode3\n",
      "Decommission Status : Normal\n",
      "Configured Capacity: 4000650883072 (3.64 TB)\n",
      "DFS Used: 135753 (132.57 KB)\n",
      "Non DFS Used: 3964090658231 (3.61 TB)\n",
      "DFS Remaining: 36560089088 (34.05 GB)\n",
      "DFS Used%: 0.00%\n",
      "DFS Remaining%: 0.91%\n",
      "Configured Cache Capacity: 0 (0 B)\n",
      "Cache Used: 0 (0 B)\n",
      "Cache Remaining: 0 (0 B)\n",
      "Cache Used%: 100.00%\n",
      "Cache Remaining%: 0.00%\n",
      "Xceivers: 0\n",
      "Last contact: Sat Jan 10 22:14:06 UTC 2026\n",
      "Last Block Report: Sat Jan 10 22:05:05 UTC 2026\n",
      "Num of Blocks: 2\n",
      "\n",
      "\n",
      "Name: 172.28.0.8:9866 (datanode2.hadoop_hadoop-network)\n",
      "Hostname: datanode2\n",
      "Decommission Status : Normal\n",
      "Configured Capacity: 4000650883072 (3.64 TB)\n",
      "DFS Used: 9246853 (8.82 MB)\n",
      "Non DFS Used: 3964081547131 (3.61 TB)\n",
      "DFS Remaining: 36560089088 (34.05 GB)\n",
      "DFS Used%: 0.00%\n",
      "DFS Remaining%: 0.91%\n",
      "Configured Cache Capacity: 0 (0 B)\n",
      "Cache Used: 0 (0 B)\n",
      "Cache Remaining: 0 (0 B)\n",
      "Cache Used%: 100.00%\n",
      "Cache Remaining%: 0.00%\n",
      "Xceivers: 0\n",
      "Last contact: Sat Jan 10 22:14:06 UTC 2026\n",
      "Last Block Report: Sat Jan 10 22:05:05 UTC 2026\n",
      "Num of Blocks: 3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check DataNode status\n",
    "!hdfs dfsadmin -report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
