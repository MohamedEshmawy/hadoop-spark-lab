{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Spark SQL - Student Version\n",
    "\n",
    "Complete the TODO sections to practice Spark SQL.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark SQL Exercise\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 1: Load Data from Multiple Formats\n",
    "- Load transactions from CSV\n",
    "- Load products from JSON\n",
    "- Register both as temporary views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load transactions CSV from HDFS\n",
    "transactions = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Load products JSON from HDFS  \n",
    "products = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Register as temp views\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(f\"Transactions: {transactions.count()}\")\n",
    "print(f\"Products: {products.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 2: Write SQL Query - Sales by Region and Month\n",
    "Write a SQL query to show total sales by store_region and month.\n",
    "Include: region, month, transaction_count, total_sales\n",
    "Order by region, then month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write the SQL query\n",
    "result = spark.sql(\"\"\"\n",
    "    -- YOUR SQL HERE\n",
    "\"\"\")\n",
    "\n",
    "result.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** Use `MONTH(TO_DATE(transaction_date, 'yyyy-MM-dd'))` to extract month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 3: Join Query - Find Top Selling Categories\n",
    "Join transactions with products to find:\n",
    "- Top 5 categories by total revenue\n",
    "- Include: category, total_transactions, total_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write the JOIN query\n",
    "top_categories = spark.sql(\"\"\"\n",
    "    -- YOUR SQL HERE\n",
    "\"\"\")\n",
    "\n",
    "top_categories.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 4: Calculate Profit Margin\n",
    "Join transactions with products and calculate:\n",
    "- Revenue per category\n",
    "- Cost per category (using cost_price * quantity)\n",
    "- Profit margin percentage = (revenue - cost) / revenue * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate profit margins by category\n",
    "profit_margins = spark.sql(\"\"\"\n",
    "    -- YOUR SQL HERE\n",
    "\"\"\")\n",
    "\n",
    "profit_margins.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 5: Write Results to Parquet\n",
    "Save the profit_margins result to HDFS in Parquet format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write to Parquet\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Verify\n",
    "!hdfs dfs -ls /user/student/output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Complex Analytics Query\n",
    "Find the best performing store_region for each category (highest total sales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS TODO: Best region per category\n",
    "# Hint: Use window functions with ROW_NUMBER()\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.11.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

